{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial, name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 28 # MNIST data input (image shape: 28*28)\n",
    "n_steps = 28 # steps\n",
    "n_hidden = 128 # number of neurons in fully connected layer \n",
    "n_classes = 10 # (0-9 digits)\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "weights = {\n",
    "    \"w_fc\" : weight_variable([n_hidden, n_classes], \"w_fc\")\n",
    "}\n",
    "biases = {\n",
    "    \"b_fc\" : bias_variable([n_classes], \"b_fc\") \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_transpose shape: (28, ?, 28)\n"
     ]
    }
   ],
   "source": [
    "x_transpose = tf.transpose(x, [1, 0, 2])\n",
    "print(\"x_transpose shape: %s\" % x_transpose.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_reshape shape: (?, 28)\n"
     ]
    }
   ],
   "source": [
    "x_reshape = tf.reshape(x_transpose, [-1, n_input])\n",
    "print(\"x_reshape shape: %s\" % x_reshape.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of x_split: <class 'list'>\n",
      "length of x_split: 28\n",
      "shape of x_split[0]: (?, 28)\n"
     ]
    }
   ],
   "source": [
    "#x_split = tf.split(0, n_steps, x_reshape)\n",
    "x_split = tf.split(x_reshape, n_steps, 0)\n",
    "print(\"type of x_split: %s\" % type(x_split))\n",
    "print(\"length of x_split: %d\" % len(x_split))\n",
    "print(\"shape of x_split[0]: %s\" % x_split[0].get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of outputs: <class 'list'>\n",
      "length of outputs: 28\n",
      "shape of h[0]: (?, 128)\n",
      "type of states: <class 'tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple'>\n"
     ]
    }
   ],
   "source": [
    "basic_rnn_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "#basic_rnn_cell = rnn.BasicRNNCell(n_hidden)\n",
    "#h, states = rnn.rnn(basic_rnn_cell, x_split, dtype=tf.float32)\n",
    "h, states = rnn.static_rnn(basic_rnn_cell, x_split, dtype=tf.float32)\n",
    "print(\"type of outputs: %s\" % type(h))\n",
    "print(\"length of outputs: %d\" % len(h))\n",
    "print(\"shape of h[0]: %s\" % h[0].get_shape())\n",
    "print(\"type of states: %s\" % type(states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_fc = tf.matmul(h[-1], weights['w_fc']) + biases['b_fc']\n",
    "y_ = h_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=h_fc,labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init_op)\n",
    "\n",
    "variables_names =[v.name for v in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 0.07132, accuracy 0.990, mean of lstm weight -0.00770, mean of lstm out -0.00633\n",
      "step 100, loss 0.12184, accuracy 0.960, mean of lstm weight -0.00770, mean of lstm out -0.00103\n",
      "step 200, loss 0.08764, accuracy 0.970, mean of lstm weight -0.00770, mean of lstm out -0.00338\n",
      "step 300, loss 0.02183, accuracy 0.990, mean of lstm weight -0.00770, mean of lstm out -0.00668\n",
      "step 400, loss 0.00406, accuracy 1.000, mean of lstm weight -0.00770, mean of lstm out -0.00752\n",
      "step 500, loss 0.00434, accuracy 1.000, mean of lstm weight -0.00770, mean of lstm out -0.01017\n",
      "step 600, loss 0.02094, accuracy 0.990, mean of lstm weight -0.00770, mean of lstm out -0.00995\n",
      "step 700, loss 0.01480, accuracy 1.000, mean of lstm weight -0.00770, mean of lstm out -0.00292\n",
      "step 800, loss 0.01319, accuracy 1.000, mean of lstm weight -0.00770, mean of lstm out -0.01078\n",
      "step 900, loss 0.04478, accuracy 0.980, mean of lstm weight -0.00770, mean of lstm out -0.00815\n",
      "step 1000, loss 0.04359, accuracy 0.990, mean of lstm weight -0.00770, mean of lstm out -0.00179\n",
      "step 1100, loss 0.03800, accuracy 0.980, mean of lstm weight -0.00770, mean of lstm out -0.00603\n",
      "step 1200, loss 0.00445, accuracy 1.000, mean of lstm weight -0.00770, mean of lstm out -0.01214\n",
      "step 1300, loss 0.11113, accuracy 0.980, mean of lstm weight -0.00770, mean of lstm out -0.00736\n",
      "step 1400, loss 0.04616, accuracy 0.980, mean of lstm weight -0.00770, mean of lstm out -0.01272\n",
      "step 2000, loss 0.12097, accuracy 0.970, mean of lstm weight -0.00770, mean of lstm out -0.01105\n",
      "step 3000, loss 0.02765, accuracy 0.990, mean of lstm weight -0.00770, mean of lstm out -0.00348\n",
      "step 4000, loss 0.01716, accuracy 0.990, mean of lstm weight -0.00770, mean of lstm out -0.01036\n"
     ]
    }
   ],
   "source": [
    "for step in range(5000):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    batch_x = np.reshape(batch_x, (batch_size, n_steps, n_input))\n",
    "    cost_train, accuracy_train, states_train, rnn_out = sess.run([cost, accuracy, states, h[-1]], feed_dict = {x: batch_x, y: batch_y})\n",
    "    values = sess.run(variables_names)\n",
    "    rnn_out_mean = np.mean(rnn_out)\n",
    "    #w_rnn_mean = np.mean(rnn_out)\n",
    "    for k,v in zip(variables_names, values):\n",
    "        if k == 'RNN/BasicLSTMCell/Linear/Matrix:0':\n",
    "            w_rnn_mean = np.mean(v)\n",
    "\n",
    "    if step < 1500:\n",
    "        if step % 100 == 0:\n",
    "            print(\"step %d, loss %.5f, accuracy %.3f, mean of lstm weight %.5f, mean of lstm out %.5f\" % (step, cost_train, accuracy_train, w_rnn_mean, rnn_out_mean))\n",
    "    else:\n",
    "        if step%1000 == 0: \n",
    "            print(\"step %d, loss %.5f, accuracy %.3f, mean of lstm weight %.5f, mean of lstm out %.5f\" % (step, cost_train, accuracy_train, w_rnn_mean, rnn_out_mean))\n",
    "    optimizer.run(feed_dict={x: batch_x, y: batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss 0.06874, accuracy 0.98050\n"
     ]
    }
   ],
   "source": [
    "cost_test, accuracy_test = sess.run([cost, accuracy], feed_dict={x: np.reshape(mnist.test.images, [-1, 28, 28]), y: mnist.test.labels})\n",
    "print(\"final loss %.5f, accuracy %.5f\" % (cost_test, accuracy_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
